What is Big O?
- Big O is the language and metric we use to describe the efficiency of algorithms.
Way of describing how the time taken by your algorithm/application grows as the input grows.

What is Time Complexity?
- A way of showing how the runtim of a function increases as the size of the input increases.

3 scenarios in case of measuring performance of any given algo:
  1. Best Case
  2. Worst Case
  3. Average Case
  
  
|   /3 
|  / /2  /1
| | /  / 
| |/ _/ 
|///________________


Big O notations:
 1.BigO : It is a complexity that is going to be less than or equal to worst case.
 2.Big Ω : It is a complexity that is going to be atleast more than the best case.
 3.Big  θ : It is a complexity that is within he bound of worst case and best case.
 
 Ex: array [n]
 
   5, 6,9,4,10,........1,3,15,2 => n elements
   and to go to next element it takes 1 millisecond then,
   BigO = O(n)    // worst case to find element is in last position
   BigΩ = Ω(1)    // best case when element is in first position
   Bigθ = θ(n/2)   // average case
   * for interiew only  focus on Big O
   
   Complexity        name                   sample
   ----------        ----                   -------
   O(1)              Constant               Accessing a specefic element in an array ex: arr[0] => fixed element hai //excellent - good
   O(n)              Linear                 Loop through arrays elements  //Fair
   O(logn)           Logarithmic            Find an element in soted array   /excellent - good
   O(n^2)            Quadratic              Looking every index of the array twice   // Bad - horrible
   O(2^n)            Exponential            Double recursion in Fibonacci   // Bad - horrible
   
 Space complexity - measure of amount of working stotage an alogorithm needs.
 How much memory in the worst case is needed at any point in the algoithm.
  Ex: array of size n => O(n) and array of size n*n => O(n^2)
 
Drop constants and non dominant terms:
 drop constants:
 O(2N) --> O(N)
 drop non dominant terms
 O(N^2+N) --> O(N^2)
 O(N+logN) --> O(N)
 O(2*2^N * 1000N^100) --> O(2^N)
As n-> infinity , constants are not a big deal
Diff computers with diff factors have diff. constant factors
Sowhen we Drop constants and non dominant terms from our expressions it becomes simpler and its easy to compare aysmptotic analysis with the simpler 
one rathetr than complex one.

Add vs Multiply in time complexity :
// here first loop is fnished hen next loop
for(a=0;arrayA.length;a++)
{
S.O.Pln(aarayA[a]);
}
for(b=0;arrayB.length;b++)            ==>    O(A+B)
{
S.O.Pln(aarayB[b]);
}

// here 
 for(a=0;arrayA.length;a++)
 {
 for(b=0;arrayB.length;b++)            ==>    O(A*B)
{
S.O.Pln(aarayB[b]+arrayA[a]);
}
 }
   
// How to measure codes using BigO
   Rule 1: Assignment statements and if stmts. that are executed once           : O(1)
           regardless of the size of the problem 
   Rule 2: A simple for loop (O to N) with no internal loop                     : O(N)        
   Rule 3: A nested loop of the same type takes Quadratic time complexity       :O(N^2)
   Rule 4: A loop in whch controlling parameter is divided by two in each step  :O(logN)
   Rule 5: when dealing with multiple statements just add them up               
   
//How to measure recursive algorithm
 public int findMaxNumRec(int[] sampleArray,int n)   ------------------------> M(N)
 {
  if(n==1){                                          ------------------------>O(1)
    return sampleArray[0];                           ------------------------>O(1)
  }
  return max(sampleArray[n-1], findMaxNumRec(int sampleArray,int n))---------->M(N-1)
 }
 
 M(N)= O(1)+M(N-1)                               M(n) = 1+M(n-1)
 M(1)=O(1)                      ===>                  = 1 + 1+ M((n-1)-1)
 M(n-1)= O(1) +M((n-1)-1)                             = 2 + M(n-2)
 M(n-2)= O(1) +M((n-2)-1)                             = 2 +1+ M((n-2)-1)
                                                      = 3 + M(n-3)
                                                      .
                                                      .
                                                      = a +M(n-a)  // make n-a =1
                                                      = n-1 + M(n-(n-1))
                                                      = n-1 + M(1)
                                                      = n -1 +1
                                                      = n
                                                      
// How to measure recursive algorithm with multiple calls
public int func( int n)
{
 if(n<=1)
 {
 return1;
 }
 return func(n-1)+func(n-1);
}

func(4) => func(3) and func(3)
each func(3) => func(2) and func(2) 
.... and so on..    ===> 2^0 + 2^1 + 2^2 + 2^3 + ......2^n = 2^(n+1) - 1
                                                           = 2^n -1 -------> O(2^n)
